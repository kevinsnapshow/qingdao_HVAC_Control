{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.externals import joblib\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# today_string = datetime.datetime.today().strftime('%Y_%m_%d')\n",
    "# df = pd.read_csv('open_data_pre_2020_06_10.csv')\n",
    "\n",
    "def import_train_data():\n",
    "    \n",
    "    global today_string\n",
    "    today_string = datetime.datetime.today().strftime('%Y_%m_%d')\n",
    "    filename = 'data_pre/open_data_' + today_string + '.csv'\n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    # 对导入的数据做了进一步的筛选，只选择 min_hour =1 & max_hour =6 \n",
    "    \n",
    "    min_hour = 1\n",
    "    max_hour = 6\n",
    "    \n",
    "    df_selected = df[(df['Δt'] >= 3600*min_hour) & (df['Δt'] <= 3600*max_hour)]\n",
    "    \n",
    "    X = df_selected.drop(['Δt','生产计划Δt','TAT7205-1T','TAT7205-1H','TAT7205-2T','TAT7205-2H','TAT7205-3T',\n",
    "                          'TAT7205-3H','TAT7205-4T','TAT7205-4H','TAT7205-5T','TAT7205-5H'], axis=1)\n",
    "    y = df_selected['Δt']\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split_validation(test_size):\n",
    "    \n",
    "    #Split the dataset into training and test datasets   \n",
    "    \n",
    "    global X_train, X_test, y_train, y_test, X_train_transform, X_test_transform \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(import_train_data()[0].set_index(keys = '时间'), import_train_data()[1], test_size=test_size,  random_state=0)\n",
    "    \n",
    "    # 数据归一化和标准化\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    X_train_transform = scaler.transform(X_train)\n",
    "    X_test_transform = scaler.transform(X_test)\n",
    "    \n",
    "    # Save scaler\n",
    "#     scaler_file_1 = \"Deployment/KT_ON/model/open_Δt_model_scaler.save\"\n",
    "#     scaler_file_2 = \"model/open_Δt_model_scaler.save\"\n",
    "    joblib.dump(scaler, \"Deployment/KT_ON/model/open_Δt_model_scaler.save\") \n",
    "    joblib.dump(scaler, \"model/open_Δt_model_scaler.save\")\n",
    "    \n",
    "    return X_train, X_train_transform, y_train, X_test, X_test_transform, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(test_size, safety_factor):\n",
    "    \n",
    "    data_split_validation(test_size)\n",
    "    \n",
    "    reg = LinearRegression().fit(X_train_transform, y_train)\n",
    "    Δt_pred = reg.predict(X_test_transform) + safety_factor*3600\n",
    "    mse_score = mean_squared_error(Δt_pred/3600, y_test/3600)\n",
    "    \n",
    "    return  reg, Δt_pred/3600, mse_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_Forest_Regression(test_size, safety_factor):\n",
    "    data_split_validation(test_size)\n",
    "\n",
    "    rfr = RandomForestRegressor()\n",
    "    rfr.fit(X_train_transform, y_train)\n",
    "    Δt_pred = rfr.predict(X_test_transform) + safety_factor*3600\n",
    "    mse_score = mean_squared_error(Δt_pred/3600, y_test/3600)\n",
    "    \n",
    "    return rfr, Δt_pred/3600, mse_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GB_Regression(test_size, safety_factor):\n",
    "    data_split_validation(test_size)\n",
    "    \n",
    "    gbr = GradientBoostingRegressor()\n",
    "    gbr.fit(X_train_transform, y_train)\n",
    "    Δt_pred = gbr.predict(X_test_transform) + safety_factor*3600\n",
    "    mse_score = mean_squared_error(Δt_pred/3600, y_test/3600)\n",
    "    \n",
    "    return gbr, Δt_pred/3600, mse_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_save(test_size, safety_factor):\n",
    "    model = GB_Regression(test_size, safety_factor)[0]\n",
    "    dump(model, 'model/open_Δt_modelSelected_'+ today_string + '.joblib') \n",
    "    dump(model, 'Deployment/KT_ON/model/open_Δt_modelSelected_'+ today_string + '.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_data():\n",
    "    X_test.to_csv('X_test_open.csv')\n",
    "    y_test.to_csv('y_test_open.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最新的GB开机训练模型已经导出\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  del sys.path[0]\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  del sys.path[0]\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    \n",
    "    test_size =0.2\n",
    "    safety_factor = 0.5\n",
    "    \n",
    "#     import_train_data()\n",
    "    data_split_validation(test_size)\n",
    "    model_save(test_size, safety_factor)\n",
    "    import_train_data()[0].to_csv('data_X_y/Open_X_'+ today_string + '.csv', index=False)\n",
    "    import_train_data()[1].to_csv('data_X_y/Open_y_'+ today_string + '.csv', index=False)\n",
    "\n",
    "    print('最新的GB开机训练模型已经导出')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Δt_plot():\n",
    "\n",
    "#     plt.boxplot([df['Δt']], patch_artist=True)\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
